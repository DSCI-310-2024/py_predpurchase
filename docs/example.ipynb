{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "\n",
    "```py_predpurchase``` can be used to:\n",
    "\n",
    "* Apply preprocessing transformations to the data, including scaling, encoding, and passing through features as specified.\n",
    "* Calculate the cross validation results for a four common off-the-shelf models (Dummy, KNN, SVM and RandomForests)\n",
    "* Fit a given model, and extract feature importances, sorted in descending order, and returns them as a DataFrame.\n",
    "* Calculate the classification metrics for model predictions including precision, recall, accuracy and F1 scores.\n",
    "\n",
    "Here, we will demonstrate each of those functionalities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.0\n"
     ]
    }
   ],
   "source": [
    "import py_predpurchase\n",
    "\n",
    "print(py_predpurchase.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages needed for the functions:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Importing functions\n",
    "from py_predpurchase.function_preprocessing import numerical_categorical_preprocess\n",
    "from py_predpurchase.function_model_cross_val import model_cross_validation\n",
    "from py_predpurchase.function_feature_importance import get_feature_importances \n",
    "from py_predpurchase.function_classification_metrics import calculate_classification_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dummy objects to give to the function\n",
    "**Note**: this is a demonstration, when using the package you will have your own objects (dataframes, models, hyperparameter values) to pass through. For the different functions, we have different kinds of dummy data. This is because these functions do not cover the entire flow of analysis, therefore the output of one function may not necessarily be the direct input of the next function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Given a dataset with both categorical and numerical data, you can use the function ```numerical_categorical_preprocess``` to preprocess all features, making them at a format that is compatible with most machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dummy dataset with both categorical and numerical data\n",
    "data = {\n",
    "    'Category': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B'],\n",
    "    'Boolean': [True, False, True, False, True, False, True, False],\n",
    "    'Numerical_1': np.random.rand(8),  # 8 random float numbers\n",
    "    'Numerical_2': np.random.randint(1, 100, 8)  # 8 random integers between 1 and 100\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# performing a train/test split \n",
    "X = df.drop('Numerical_2', axis=1)\n",
    "y = df['Numerical_2']\n",
    "\n",
    "\n",
    "# test_size=0.25, 0.75 for train set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining numerical and categorical features\n",
    "numeric_features = [\"Numerical_1\"]\n",
    "categorical_features = [\"Category\", \"Boolean\"]\n",
    "\n",
    "# applying the numerical_categorical_preprocess function\n",
    "preprocessed_data = numerical_categorical_preprocess(\n",
    "    X_train, \n",
    "    X_test, \n",
    "    y_train,\n",
    "    y_test,\n",
    "    numeric_features, \n",
    "    categorical_features\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "The ```model_cross_validation``` function Calculates the cross validation results for a four common off-the-shelf models (Dummy, KNN, SVM and RandomForests) using preprocessed and cleaned training and testing datasets. Random forests and Dummy hyperparameters are fixed for simplicity sake.\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dummy dataset\n",
    "\n",
    "train_data = pd.DataFrame({\n",
    "    \"feature1\": [1, 2, 3, 4, 5, 2, 2, 3, 3, 3, 3],\n",
    "    \"feature2\": [5, 4, 3, 2, 1, 4, 0, 5, 5, 5, 5],\n",
    "    'target': [0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
    "})\n",
    "\n",
    "test_data = pd.DataFrame({\n",
    "    \"feature1\": [1, 2, 3, 4, 5, 2, 2, 3, 3, 3, 3],\n",
    "    \"feature2\": [5, 4, 3, 2, 1, 4, 0, 5, 5, 5, 5],\n",
    "    'target': [0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>knn</th>\n",
       "      <th>SVM</th>\n",
       "      <th>random_forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.001 (+/- 0.000)</td>\n",
       "      <td>0.002 (+/- 0.001)</td>\n",
       "      <td>0.003 (+/- 0.001)</td>\n",
       "      <td>0.057 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.001 (+/- 0.001)</td>\n",
       "      <td>0.004 (+/- 0.001)</td>\n",
       "      <td>0.002 (+/- 0.001)</td>\n",
       "      <td>0.004 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.533 (+/- 0.075)</td>\n",
       "      <td>0.467 (+/- 0.075)</td>\n",
       "      <td>0.367 (+/- 0.217)</td>\n",
       "      <td>0.367 (+/- 0.217)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.544 (+/- 0.025)</td>\n",
       "      <td>0.569 (+/- 0.084)</td>\n",
       "      <td>0.750 (+/- 0.048)</td>\n",
       "      <td>0.750 (+/- 0.048)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         dummy                knn                SVM  \\\n",
       "fit_time     0.001 (+/- 0.000)  0.002 (+/- 0.001)  0.003 (+/- 0.001)   \n",
       "score_time   0.001 (+/- 0.001)  0.004 (+/- 0.001)  0.002 (+/- 0.001)   \n",
       "test_score   0.533 (+/- 0.075)  0.467 (+/- 0.075)  0.367 (+/- 0.217)   \n",
       "train_score  0.544 (+/- 0.025)  0.569 (+/- 0.084)  0.750 (+/- 0.048)   \n",
       "\n",
       "                 random_forest  \n",
       "fit_time     0.057 (+/- 0.003)  \n",
       "score_time   0.004 (+/- 0.001)  \n",
       "test_score   0.367 (+/- 0.217)  \n",
       "train_score  0.750 (+/- 0.048)  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining dummy hyperparameters\n",
    "target = \"target\"\n",
    "k = 5\n",
    "gamma = 10\n",
    "\n",
    "cross_val_results = model_cross_validation(train_data, \n",
    "                                           test_data, \n",
    "                                           target, \n",
    "                                           k, \n",
    "                                           gamma)\n",
    "\n",
    "pd.DataFrame(cross_val_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Given an X and y (explanatory and target features) dataframe, the function ```get_feature_importances``` fits the model, extracts feature importances, sorts them, and returns them as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>0.504683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature1</th>\n",
       "      <td>0.495317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Importance\n",
       "feature2    0.504683\n",
       "feature1    0.495317"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dummy mdoel\n",
    "model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "#dummy data\n",
    "X_data = pd.DataFrame({\n",
    "    \"feature1\": [1, 2, 3, 4, 5, 2, 2, 3, 3, 3, 3],\n",
    "    \"feature2\": [5, 4, 3, 2, 1, 4, 0, 5, 5, 5, 5],\n",
    "})\n",
    "\n",
    "y_data = [0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
    "\n",
    "# fitting the dummy model\n",
    "\n",
    "model.fit(X_data, y_data)\n",
    "\n",
    "X_columns = [\"feature1\", \"feature2\"]\n",
    "\n",
    "get_feature_importances(model, X_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics\n",
    "Given the true value and the predictive target value (output from a chosen model's prediction), the ```calculate_classification_metrics``` function calculates classification metrics for model predictions including precision, recall, accuracy and F1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.7200000000000001,\n",
       " 'Recall': 0.7,\n",
       " 'Accuracy': 0.7,\n",
       " 'F1 Score': 0.7030303030303029}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy data\n",
    "\n",
    "y_true = [1,0,1,1,1,0,0,1,0,1]\n",
    "y_pred = [1,1,1,0,1,0,0,1,0,0]\n",
    "\n",
    "calculate_classification_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
